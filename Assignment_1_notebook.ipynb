{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436313d4-1d62-4d08-876c-d68489a00020",
   "metadata": {},
   "source": [
    "# Analysing Data - Assignment 1\n",
    "Henry Alexander Hornung (S4156145)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033c6159-e2e0-4284-89b6-adf5fbda5bdd",
   "metadata": {},
   "source": [
    "## Downloading and Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b49ec-13a4-4745-9210-11c2e785ff66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ensuring that all necessary packages and resources are downloaded\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download nl_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60a1ef-21b3-482a-9eb6-bb5c073dab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb43fc-6bfa-465c-b513-427fe4f2dc5a",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef3c0c6-5ae8-44a0-afd4-154b46c48ff8",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "Perform sentence splitting and word tokenization. Report the statistics of word frequency (per story and in total) in a python dictionary, plot the 25 most common words (per story and in total) in the form of a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d1874-7afa-4947-9358-38f949c40065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing files for part 1\n",
    "part1 = []\n",
    "for filename in os.listdir(\"Part_I_1-2/\"):\n",
    "    if filename != \".DS_Store\":\n",
    "        with open(\"Part_I_1-2/\" + filename, encoding = \"utf-8\") as file:\n",
    "            content = file.read()\n",
    "        part1.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1cc95-b18d-4b86-8876-22b3f0b416bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing title from each text, saving it under metadata list\n",
    "metadata = []\n",
    "for index, text in enumerate(part1):\n",
    "    metadata.append(text.split(\"---\")[0])\n",
    "    if \"---\" in text:\n",
    "        part1[index] = text.split(\"---\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea580591-499c-40e2-bfa2-90c1b9a6f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence tokenizing\n",
    "part1_sent = []\n",
    "for text in part1:\n",
    "    part1_sent.append(sent_tokenize(text))\n",
    "\n",
    "# Word tokenizing\n",
    "part1_word = []\n",
    "for text in part1:\n",
    "    part1_word.append(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8045e1-35d6-4090-a4bb-e3e03f069360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word frequencies function\n",
    "def getwf(text):\n",
    "    wf = {}\n",
    "    punct = \"“”.,?'’!''``\"\n",
    "    \n",
    "    # Getting the total occurances of each word\n",
    "    for word in text:\n",
    "        if word not in punct:\n",
    "            if word.lower() not in wf.keys():\n",
    "                wf[word.lower()] = 1\n",
    "            else:\n",
    "                wf[word.lower()] += 1\n",
    "\n",
    "    # Transforming the word counts into word frequencies\n",
    "    total_words = len(wf.keys())\n",
    "    for word, occurances in wf.items():\n",
    "        wf[word] = occurances/total_words\n",
    "\n",
    "    # Sorting them from highest to lowest, including only the top 25 most common words.\n",
    "    wf = dict(sorted(wf.items(), key=lambda x: x[1], reverse=True)[:25])\n",
    "    \n",
    "    return wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e5e7c-f3eb-410f-a504-b8812e1c4371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word frequencies total\n",
    "word_total = []\n",
    "for text in part1_word:\n",
    "    for word in text:\n",
    "        word_total.append(word)\n",
    "\n",
    "wf_total = getwf(word_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8609a69-a08f-42b1-bf0c-fd865676c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word frequencies per story\n",
    "wf_01 = getwf(part1_word[0])\n",
    "wf_02 = getwf(part1_word[1])\n",
    "wf_03 = getwf(part1_word[2])\n",
    "wf_04 = getwf(part1_word[3])\n",
    "wf_05 = getwf(part1_word[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b4e30-a1ae-4f54-b9e3-e9a9d129b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word frequencies total\n",
    "word_total = []\n",
    "for text in part1_word:\n",
    "    for word in text:\n",
    "        word_total.append(word)\n",
    "\n",
    "wf_total = getwf(word_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586842b0-de29-4010-b3a6-eb40f1c158ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create/export the histogram\n",
    "def get_wf_hist(dictionary, title, file_name):\n",
    "    words = list(dictionary.keys())\n",
    "    frequencies = list(dictionary.values())\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(words, frequencies)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filepath = os.path.join(\"Figures\", file_name)\n",
    "    \n",
    "    return (plt.savefig(filepath), plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64620d83-4ffa-46d0-bd45-38fa7207c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ouput the frequencies in a df\n",
    "def createDF(wf_list):\n",
    "    wf_df = pd.DataFrame()\n",
    "\n",
    "    for dictionary, text in wf_list:\n",
    "        # Saving the words and frequencies as pd series respectively\n",
    "        words = pd.Series(dictionary.keys(), name = text + \" words\")\n",
    "        frequencies = pd.Series(dictionary.values(), name = text + \" freq\")\n",
    "    \n",
    "        # Adding the series to a df, and subsequently concating this with the final df\n",
    "        temp_df = pd.concat([words, frequencies], axis = 1)\n",
    "        wf_df = pd.concat([wf_df, temp_df], axis = 1)\n",
    "    \n",
    "    # Displaying the final df\n",
    "    return wf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932f704-f548-4622-9480-ad70d66e3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving each frequency dictionary in a tuple with its corresponding text to assign the titles of the columns\n",
    "wf_list = [(wf_01, \"Text 1\"), (wf_02, \"Text 2\"), (wf_03, \"Text 3\"), (wf_04, \"Text 4\"), (wf_05, \"Text 5\"), (wf_total, \"Total\")]\n",
    "\n",
    "# Displaying the most frequent words, along with their frequencies\n",
    "createDF(wf_list).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739863c5-45ed-483d-8155-a5cc905b630b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Outputting each histogram\n",
    "get_wf_hist(wf_01, metadata[0]+\" Most Frequent Words\", \"fig1\")\n",
    "get_wf_hist(wf_02, metadata[1]+\" Most Frequent Words\", \"fig2\")\n",
    "get_wf_hist(wf_03, metadata[2]+\" Most Frequent Words\", \"fig3\")\n",
    "get_wf_hist(wf_04, metadata[3]+\" Most Frequent Words\", \"fig4\")\n",
    "get_wf_hist(wf_05, metadata[4]+\" Most Frequent Words\", \"fig5\")\n",
    "get_wf_hist(wf_total, \"Most Frequent Words Total\", \"fig6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5089c-6edf-418a-b774-a782b93a8d7d",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "Perform stemming on the text using the Porter and Lancaster stemmer. Re-create the statistics and the plot from 1. Compare the differences between the stemmed and unstemmed results, and discuss the difference in the results of the two stemmers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9a387-2e29-499b-b6c3-363b77b00cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply porter stemmer to list of words\n",
    "def Pstemmer(tokenized_text):\n",
    "    Porter = PorterStemmer()\n",
    "    stemmed_words = []\n",
    "    \n",
    "    for word in tokenized_text:\n",
    "        stemmed_words.append(Porter.stem(word))\n",
    "    \n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14d7cc-5fc1-42ef-8fad-4249b1297d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply lancaster stemmer to list of words\n",
    "def Lstemmer(tokenized_text):\n",
    "    Lancaster = LancasterStemmer()\n",
    "    stemmed_words = []\n",
    "    \n",
    "    for word in tokenized_text:\n",
    "        stemmed_words.append(Lancaster.stem(word))\n",
    "    \n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80202025-e866-4eb8-9780-0149cf4343d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying both stemmers to the texts\n",
    "porter_01 = Pstemmer(part1_word[0])\n",
    "porter_02 = Pstemmer(part1_word[1])\n",
    "porter_03 = Pstemmer(part1_word[2])\n",
    "porter_04 = Pstemmer(part1_word[3])\n",
    "porter_05 = Pstemmer(part1_word[4])\n",
    "porter_total = Pstemmer(word_total)\n",
    "\n",
    "lancaster_01 = Lstemmer(part1_word[0])\n",
    "lancaster_02 = Lstemmer(part1_word[1])\n",
    "lancaster_03 = Lstemmer(part1_word[2])\n",
    "lancaster_04 = Lstemmer(part1_word[3])\n",
    "lancaster_05 = Lstemmer(part1_word[4])\n",
    "lancaster_total = Lstemmer(word_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87a9bb-303f-4562-9595-31760203a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the word frequencies for each stemmed text\n",
    "porter_wf_01 = getwf(porter_01)\n",
    "porter_wf_02 = getwf(porter_02)\n",
    "porter_wf_03 = getwf(porter_03)\n",
    "porter_wf_04 = getwf(porter_04)\n",
    "porter_wf_05 = getwf(porter_05)\n",
    "porter_wf_total = getwf(porter_total)\n",
    "\n",
    "lancaster_wf_01 = getwf(lancaster_01)\n",
    "lancaster_wf_02 = getwf(lancaster_02)\n",
    "lancaster_wf_03 = getwf(lancaster_03)\n",
    "lancaster_wf_04 = getwf(lancaster_04)\n",
    "lancaster_wf_05 = getwf(lancaster_05)\n",
    "lancaster_wf_total = getwf(lancaster_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd362a-1922-4b4c-bc92-ff5579aa5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting the porter-stemmed frequencies in df\n",
    "porter_list = [(porter_wf_01, \"Text 1\"), (porter_wf_02, \"Text 2\"), (porter_wf_03, \"Text 3\"), (porter_wf_04, \"Text 4\"), (porter_wf_05, \"Text 5\"), (porter_wf_total, \"Total\")]\n",
    "\n",
    "createDF(porter_list).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b874d-8fef-4e59-a115-059b899d8b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generating the histograms for the porter-stemmed texts\n",
    "porter_wfs = [porter_wf_01, porter_wf_02, porter_wf_03, porter_wf_04, porter_wf_05, porter_wf_total]\n",
    "n = 7\n",
    "\n",
    "for index, wf in enumerate(porter_wfs):\n",
    "    if index <= 4:\n",
    "        get_wf_hist(wf, \"WF with porter stemmer: Text \" + str(index+1), f\"fig{n}\")\n",
    "        n += 1\n",
    "    else:\n",
    "        get_wf_hist(wf, \"WF with porter stemmer: Total\", f\"fig{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bafccb-dca3-4c56-ae35-20e4ee3f433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same for the lancaster-stemmed texts\n",
    "lancaster_list = [(lancaster_wf_01, \"Text 1\"), (lancaster_wf_02, \"Text 2\"), (lancaster_wf_03, \"Text 3\"), (lancaster_wf_04, \"Text 4\"), (lancaster_wf_05, \"Text 5\"), (lancaster_wf_total, \"Total\")]\n",
    "\n",
    "createDF(lancaster_list).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f114cb9-1821-48c4-b2ee-7eeaa206dc25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lancaster_wfs = [lancaster_wf_01, lancaster_wf_02, lancaster_wf_03, lancaster_wf_04, lancaster_wf_05, lancaster_wf_total]\n",
    "n = 13\n",
    "\n",
    "for index, wf in enumerate(lancaster_wfs):\n",
    "    if index <= 4:\n",
    "        get_wf_hist(wf, \"WF with lancaster stemmer: Text \" + str(index+1), f\"fig{n}\")\n",
    "        n += 1\n",
    "    else:\n",
    "        get_wf_hist(wf, \"WF with lancaster stemmer: Total\", f\"fig{n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420b0b90-6b77-4e9e-a0fc-050e0f6f6d11",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "In Brightspace, you will find three translations of Tom Sawyer by Mark Twain. After cleaning the document (e.g. removing the preamble, TOC, licensing information …), use the appropriate spacy models to derive the POS-tags of the text. Report the frequencies of the tags for the three languages. What assumptions do you make based on the findings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94242950-9d64-4fcd-aa23-4d577c8dad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the texts\n",
    "part1_3 = []\n",
    "for filename in os.listdir(\"Part_I_3/\"):\n",
    "    if filename != \".DS_Store\":\n",
    "        with open(\"Part_I_3/\" + filename, encoding = \"utf-8\") as file:\n",
    "            content = file.read()\n",
    "        part1_3.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c07ff-1c2d-4c64-b5ac-e4f24721aad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing the text at the beginning and end of the documents\n",
    "for text in part1_3:\n",
    "    text = text.split(\"*** END OF THE PROJECT GUTENBERG EBOOK\")[0]\n",
    "    if \"Erstes Kapitel.\" in text:\n",
    "        de_text = text.split(\"Erstes Kapitel.\")[1]\n",
    "    elif \"HOOFDSTUK I.\" in text:\n",
    "        nl_text = text.split(\"HOOFDSTUK I.\")[1]\n",
    "    elif \"CHAPTER I.\":\n",
    "        en_text = text.split(\"\\n\\n\\n\\nCHAPTER I\\n\")[1]\n",
    "\n",
    "# Removing excess line breaks\n",
    "de_text = re.sub(r'\\n{1,}', ' ', de_text)\n",
    "nl_text = re.sub(r'\\n{1,}', ' ', nl_text)\n",
    "en_text = re.sub(r'\\n{1,}', ' ', en_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf8d66-f52c-44b6-88d7-c4d851e3a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing English text and getting POS tags using SpaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "sawyer_en_tokenized = [token.text for token in nlp(en_text)]\n",
    "sawyer_en_pos = [token.pos_ for token in nlp(en_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c513f-55dd-492a-bcdd-110c162f4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing German text and getting POS tags using SpaCy\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "sawyer_de_tokenized = [token.text for token in nlp(de_text)]\n",
    "sawyer_de_pos = [token.pos_ for token in nlp(de_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6028770-ee71-4f42-aec6-db8e373f809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Duch text and getting POS tags using SpaCy\n",
    "nlp = spacy.load('nl_core_news_sm')\n",
    "\n",
    "sawyer_nl_tokenized = [token.text for token in nlp(nl_text)]\n",
    "sawyer_nl_pos = [token.pos_ for token in nlp(nl_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad008d2e-caa1-4a54-84fd-bf44a0fe1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tokenized texts and POS tags to a df\n",
    "df_en = pd.DataFrame()\n",
    "df_en[\"text_en\"] = sawyer_en_tokenized\n",
    "df_en[\"POS_en\"] = sawyer_en_pos\n",
    "\n",
    "df_de = pd.DataFrame()\n",
    "df_de[\"text_de\"] = sawyer_de_tokenized\n",
    "df_de[\"POS_de\"] = sawyer_de_pos\n",
    "\n",
    "df_nl = pd.DataFrame()\n",
    "df_nl[\"text_nl\"] = sawyer_nl_tokenized\n",
    "df_nl[\"POS_nl\"] = sawyer_nl_pos\n",
    "\n",
    "sawyer_df = pd.concat([df_en, df_de, df_nl], axis=1)\n",
    "sawyer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65470f-f5a2-4ef9-955d-44455f1c7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the frequencies of each tag\n",
    "def posfreq(pos):\n",
    "    pos_dict = {}\n",
    "    for tag in pos:\n",
    "        if tag not in pos_dict.keys():\n",
    "            pos_dict[tag] = 1\n",
    "        else:\n",
    "            pos_dict[tag] += 1\n",
    "    total_tags = sum(pos_dict.values())\n",
    "\n",
    "    for word, occurances in pos_dict.items():\n",
    "        pos_dict[word] = occurances/total_tags\n",
    "    \n",
    "    return pos_dict\n",
    "\n",
    "en_freq = posfreq(sawyer_en_pos)\n",
    "de_freq = posfreq(sawyer_de_pos)\n",
    "nl_freq = posfreq(sawyer_nl_pos)\n",
    "\n",
    "# Presenting frequencies in a df\n",
    "pos_freq_df = pd.DataFrame({'English': en_freq, 'German': de_freq, 'Dutch': nl_freq})\n",
    "pos_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edffd28-cb63-4059-81a3-dd7313542ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining function to plot POS tags on a histogram\n",
    "def get_pos_hist(dictionary, title, file_name):\n",
    "    words = list(dictionary.keys())\n",
    "    frequencies = list(dictionary.values())\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(words, frequencies)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Tags\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filepath = os.path.join(\"Figures\", file_name)\n",
    "    \n",
    "    return (plt.savefig(filepath), plt.show())\n",
    "\n",
    "# Applying the function\n",
    "get_pos_hist(dict(sorted(en_freq.items(), key=lambda x: x[1], reverse=True)), \"English Text POS Tags\", \"fig19\")\n",
    "get_pos_hist(dict(sorted(de_freq.items(), key=lambda x: x[1], reverse=True)), \"German Text POS Tags\", \"fig20\")\n",
    "get_pos_hist(dict(sorted(nl_freq.items(), key=lambda x: x[1], reverse=True)), \"Dutch Text POS Tags\", \"fig21\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488108c-5031-4782-88d2-6bb094365f99",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99277f2b-76f3-4924-ae56-6708714f52c5",
   "metadata": {},
   "source": [
    "On the data for Part I (1+2), perform Named Entity Recognition using spacy. Annotate a small data set of 1-2 sentences per text with named entity categories. (The sentences are supposed to include names of characters, places and other entities.)\n",
    "\n",
    "How good or bad is the performance of the automatic method on the manually annotated text? Report Precision, Recall, F1 Score and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d1f48-62a5-4754-8342-849f81f6a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-loading the English core\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c9be2-9480-44e4-816a-6bf2722abcc0",
   "metadata": {},
   "source": [
    "#### Text 1: Another plot? - Bones_Bard "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f259b-6950-4a29-919b-53deb516f11f",
   "metadata": {},
   "source": [
    "##### Automatic NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea92a71-2b09-48fb-8f14-8cefedccdd24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text 1 automatic NER\n",
    "doc = nlp(part1[0])\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a866b-5abd-4841-a90c-89eb0fba761e",
   "metadata": {},
   "source": [
    "##### Manual NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07240903-6f7b-4cb7-9b22-93305c735a43",
   "metadata": {},
   "source": [
    "\"(Missy: PER) was sitting on a chair in a house, maps and papers spread around, normally her planning was mental, but (River: PER) had suggested a physical map to refer to and it was helpful. (River: PER) walked out of the bedroom. “The people who own this house really have no good clothes.” She was wearing a t-shirt that drenched her form, and some trousers that looked about the right size, (Missy: PER) smiled, still in her (Mary Poppins: PER) looking outfit, (River: PER) looked over at the maps.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c241f38-28c8-407e-a1df-4eda48926ece",
   "metadata": {},
   "source": [
    "#### Text 2: You’d looked me in my eyes and told me - Bones_Bard "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e13a41-16b0-4cae-93d1-f9b003df0622",
   "metadata": {},
   "source": [
    "##### Automatic NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd67f4-9935-4448-88d2-7a11eeb85012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text 2 automatic NER\n",
    "doc = nlp(part1[1])\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469b2a3-fed5-4b80-a026-3b5cb6ff585e",
   "metadata": {},
   "source": [
    "##### Manual NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0376b2b9-cf28-4774-9e4f-fcbdd4253e1d",
   "metadata": {},
   "source": [
    "\"She sat in her bed, thinking over how she got here, her husband, a man, and occasionally women, she loved, who also made her want to slap him, he hadn’t known who she was, she thought back to something she once told her father, well, (the Doctor: PER) not knowing who she was had killed her. She took a book from her bedside table, she was surrounded by them these day, she whispered to herself. “It’s a bit boring with those trips, isn’t it.” She didn’t expect anyone to agree, and nobody did.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12f2f0b7-f991-4ff9-b5f2-1747eb750b83",
   "metadata": {},
   "source": [
    "#### Text 3: I Want You Safe - Beegabbagabba "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ac72a-42b2-4951-be20-6e8ae64fd9de",
   "metadata": {},
   "source": [
    "##### Automatic NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2e3e1-f4f5-42da-86a9-1e72e5da5066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text 3 automatic NER\n",
    "doc = nlp(part1[2])\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ec863-2512-464e-8083-bef01322037b",
   "metadata": {},
   "source": [
    "##### Manual NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e1ca57-46f7-4620-91ad-c52dc1ddd80c",
   "metadata": {},
   "source": [
    "\"(Rose Tyler: PER).\" (Rassilon: PER), how he loved to say her name. \"I was going to take you to so many places. (Barcelona: LOC). Not the city (Barcelona: LOC/GPE), the planet (Barcelona: LOC). You'd love it. Fantastic place! They've got dogs with no noses! Imagine how many times a day you end up tellin' that joke and it's still funny!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c708a0-9fc9-4693-a276-8c3e81f4d30a",
   "metadata": {},
   "source": [
    "#### Text 4: Even If the Language of Flowers is Dead, Roses Always Mean Love - aubreyplvr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110485c6-4409-4431-947b-82326d1b6edc",
   "metadata": {},
   "source": [
    "##### Automatic NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a817d89-8766-428b-b845-a12807cb5e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text 4 automatic NER\n",
    "doc = nlp(part1[3])\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b7ec77-4b56-4f45-85a8-ab80d9b5772b",
   "metadata": {},
   "source": [
    "##### Manual NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e5689-44e1-47ea-b97e-c3c8148580d3",
   "metadata": {},
   "source": [
    "\"The TARDIS wasn’t meant to translate (Gallifreyan: LANG) to other languages. So, very early on, (The Doctor: PER) had adjusted some things so she could translate (Gallifreyan: LANG) to (English: LANG). The system had to be repaired regularly, but it was worth it for people like (Rose: PER).\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113af42c-64c1-4e59-a402-1b8354070653",
   "metadata": {},
   "source": [
    "#### Text 5: WWTDD: What would the Doctor do? - aboutcustardcreams "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add30b00-49e3-4f29-95fa-ac4a03b7eaa2",
   "metadata": {},
   "source": [
    "##### Automatic NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a732359-c627-40fa-9355-6830c75c71a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text 5 automatic NER\n",
    "doc = nlp(part1[4])\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15f237-fcbf-4e35-b80c-e9caa01b1704",
   "metadata": {},
   "source": [
    "##### Manual NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234647b2-f5cc-4de4-b600-42ec1741cbc3",
   "metadata": {},
   "source": [
    "\"You didn’t mean to be away for long, however, spending some time alone allowed you to really focus on (the Doctor: PER)’s words. And you realized all this time she had been right. She was always right and it was annoying. You couldn’t rely on violence for whatever reason, so you made use of the time alone to fix yourself. You never thought you’d do that for anything or anyone, yet you were willing to change for her. You had a vortex manipulator to move around and that’s what you used to answer distress calls all over the (Universe: LOC).\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
